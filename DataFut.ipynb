{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7b66fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!pip install opencv-contrib-python\n",
    "#!pip install scikit-learn\n",
    "#!pip install scikit-image\n",
    "#!pip install imutils\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee5e51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#leitura do arquivo\n",
    "\n",
    "#data=pd.read_csv('BRA.csv', delimiter=',')\n",
    "# ou:\n",
    "data=pd.read_csv('/home/marcelo-pinto/projects/python/DataFut/BRA.csv', delimiter=',')\n",
    "\n",
    "#verificando os primeiros...\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74999334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#explorando os dados\n",
    "\n",
    "matches = data.shape[0]\n",
    "\n",
    "features = data.shape[1] -1\n",
    "\n",
    "home_win = len(data[data.Res==1])\n",
    "away_win = len(data[data.Res==2])\n",
    "draw = len(data[data.Res==0])\n",
    "val=[home_win, away_win, draw]\n",
    "\n",
    "win_rate = (float(home_win)/(matches)) * 100\n",
    "\n",
    "print('Total de jogos:', matches)\n",
    "print('Total de colunas:', features)\n",
    "print('Total de jogos ganhos em casa:', home_win)\n",
    "print('Total de jogos ganhos pelo visitante:', away_win)\n",
    "print('Total de jogos empatados:', draw)\n",
    "print('Percentual de jogos ganhos em casa: {:.2f}%'.format( win_rate ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1ea57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(3)\n",
    "plt.bar(x, val)\n",
    "plt.xticks(x, ('Home', 'Away', 'Draw'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bdc050",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deixar somente variáveis numéricas\n",
    "\n",
    "num_data = data.drop(['Country', 'League', 'Season', 'Date', 'Time', 'Home', 'Away'],1)\n",
    "\n",
    "display(num_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7dfef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = num_data.drop(['Res'],1)\n",
    "\n",
    "labels = num_data['Res']\n",
    "\n",
    "print('Features')\n",
    "print(features.head())\n",
    "\n",
    "print('=========')\n",
    "\n",
    "print('Labels')\n",
    "print(labels.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9038670",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ('HG', 'AG', 'PH', 'PD', 'PA', 'MaxH', 'MaxD', 'MaxA', 'AvgH', 'AvgD', 'AvgA')\n",
    "\n",
    "k_best_features = SelectKBest(k='all')\n",
    "k_best_features.fit_transform(features, labels)\n",
    "k_best_features_scores = k_best_features.scores_\n",
    "raw_pairs = zip(features_list[1:], k_best_features_scores)\n",
    "ordered_pairs = list(reversed(sorted(raw_pairs, key=lambda x: x[1])))\n",
    "\n",
    "\n",
    "k_best_features_final = dict(ordered_pairs[:15])\n",
    "best_features = k_best_features_final.keys()\n",
    "print('')\n",
    "print('Melhores features:')\n",
    "print(k_best_features_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb154cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = num_data.drop(['Res', 'game_id', 'home_id', 'Away_id', 'AG', 'PD', 'PH'],1)\n",
    "\n",
    "labels = num_data['Res']\n",
    "\n",
    "print('Features')\n",
    "print(features.head())\n",
    "\n",
    "print('=========')\n",
    "\n",
    "print('Labels')\n",
    "print(labels.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c8ba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#novo padrão\n",
    "scaler = MinMaxScaler().fit(features)\n",
    "features_scale = scaler.transform(features)\n",
    "\n",
    "print('Features: ', features_scale.shape)\n",
    "print(features_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbff0a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = features_scale[:1932]\n",
    "X_test = features_scale[1932:2155]\n",
    "y_train = labels[:1932]\n",
    "y_test = labels[1932:2155]\n",
    "\n",
    "print( len(X_train), len(y_train))\n",
    "\n",
    "print( len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bf7eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('LogisticRegression')\n",
    "\n",
    "\n",
    "clf_LR = LogisticRegression(multi_class='multinomial',max_iter=2000)\n",
    "clf_LR.fit(X_train, y_train)\n",
    "pred= clf_LR.predict(X_test)\n",
    "\n",
    "lg_acc = accuracy_score(y_test,  pred)\n",
    "f1=f1_score(y_test,pred,average = 'micro')\n",
    "print ('Acurácia LogisticRegression:{}'.format(lg_acc))\n",
    "print ('F1 Score:{}'.format(f1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cb9bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parâmetros\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "\n",
    "search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid)\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "clf = search.best_estimator_\n",
    "pred= clf.predict(X_test)\n",
    "lg_acc = accuracy_score(y_test, pred)\n",
    "\n",
    "\n",
    "f1=f1_score(y_test,pred,average = 'macro')\n",
    "\n",
    "print ('Acurácia LogisticRegression:{}'.format(lg_acc))\n",
    "print ('F1 Score:{}'.format(f1) )\n",
    "\n",
    "print (clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e33dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SVC')\n",
    "\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "pred= clf.predict(X_test)\n",
    "\n",
    "svc_acc = accuracy_score(y_test, pred)\n",
    "f1=f1_score(y_test,pred, average='micro')\n",
    "print ('Acurácia SVC:{}'.format(svc_acc))\n",
    "print ('F1 Score:{}'.format(f1) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15cb803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hiper parâmetros\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "\n",
    "search = GridSearchCV(SVC(), param_grid)\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "clf_SVC = search.best_estimator_\n",
    "pred= clf_SVC.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "\n",
    "f1=f1_score(y_test, pred, average = 'micro')\n",
    "\n",
    "print ('F1 Score:{}'.format(f1))\n",
    "\n",
    "print ('Acurácia LogisticRegression{}'.format(acc))\n",
    "\n",
    "print (clf_SVC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b85b1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Decision Tree')\n",
    "\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "pred= clf.predict(X_test)\n",
    "\n",
    "dt_acc = accuracy_score(y_test, pred)\n",
    "f1=f1_score(y_test, pred, average='macro')\n",
    "print ('Acurácia Tree:{}'.format(dt_acc))\n",
    "print ('F1 Score:{}'.format(f1) )\n",
    "\n",
    "\n",
    "n_estimators = [10, 50, 100, 200]\n",
    "max_depth = [3, 10, 20, 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82bdada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testes de parâmetros\n",
    "\n",
    "print('Decision Tree')\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12]\n",
    "}\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "clf = search.best_estimator_\n",
    "pred= clf.predict(X_test)\n",
    "dt_acc = accuracy_score(y_test, pred)\n",
    "\n",
    "\n",
    "f1=f1_score(y_test, pred, average = 'micro')\n",
    "\n",
    "\n",
    "print ('Acurácia Decision Tree:{}'.format(dt_acc))\n",
    "print ('F1 Score:{}'.format(f1))\n",
    "\n",
    "print (clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528aa82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#treinando e testando os modelos\n",
    "\n",
    "print ('Naive Baeys')\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "pred= clf.predict(X_test)\n",
    "\n",
    "nb_acc = accuracy_score(y_test, pred)\n",
    "f1=f1_score(y_test, pred, average='micro')\n",
    "print('Acurácia Naive Baeys:{}'.format(nb_acc))\n",
    "print('F1 Score:{}'.format(f1) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abe895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#executando previsão:\n",
    "\n",
    "previsao=features_scale[2155:]\n",
    "\n",
    "\n",
    "game_id_full=data['game_id']\n",
    "game_id=game_id_full[2155:]\n",
    "\n",
    "res_full=data['Res']\n",
    "res=res_full[2155:]\n",
    "\n",
    "pred=clf_SVC.predict(previsao)\n",
    "\n",
    "df=pd.DataFrame({'real': res, 'previsao':pred, 'game_id': game_id})\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346a0fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#método confusion Matrix\n",
    "\n",
    "df=pd.DataFrame(df,columns=['real', 'previsao'])\n",
    "\n",
    "cf_matrix=pd.crosstab(df['real'], df['previsao'], rownames=['real'], colnames=['previsao'])\n",
    "\n",
    "sns.heatmap(cf_matrix, annot=True, cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c300b9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
